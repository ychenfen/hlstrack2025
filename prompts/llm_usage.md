# 大模型使用记录

## 使用的LLM

- **模型名称**: Claude 3.5 Sonnet (Anthropic)
- **使用方式**: Claude Code (VSCode Extension)
- **使用时间**: 2025年10月26日 - 2025年10月29日

---

## 优化过程总览

### 第一阶段：初始分析和环境准备（10月26日）

**任务**: 理解竞赛要求，分析三个算法的baseline代码

**与LLM的交互**:
1. 让LLM分析README.md和评分规则
2. 了解HLS优化的基本方法论
3. 分析三个算法的代码结构和优化空间

**LLM输出**:
- 评分公式分析
- 三个算法的优化建议
- HLS pragma的使用指南

### 第二阶段：保守优化尝试（10月27日）

**任务**: 应用基础优化，确保功能正确

**与LLM的交互**:
1. 询问HLS PIPELINE和DATAFLOW的最佳实践
2. 讨论数组分区策略
3. 解决编译错误和功能测试失败

**应用的优化**:
- Cholesky: 基础的cyclic数组分区
- LZ4: 流深度调整
- SHA-256: 保持baseline

**测试结果**:
- SHA-256: 690 → 684 (小幅改进)
- LZ4: 4784 → 4720 (小幅改进)
- Cholesky: 7015 → 6983 (小幅改进)
- 总分: 约1.008 (几乎无提升)

### 第三阶段：现实检查和策略调整（10月28日）

**任务**: 评估获奖可能性，制定激进优化策略

**与LLM的交互**:
1. 要求LLM分析当前成绩的获奖可能性
2. LLM给出实事求是的分析：1.008分几乎不可能获奖
3. 讨论激进优化的风险和收益

**LLM的关键建议**:
- 竞赛评分是相对的，需要假设最强对手会优化30-50%
- 保守优化得分太低，必须采用激进策略
- 重点突破Cholesky（35%权重）

### 第四阶段：激进优化实施（10月29日）

**任务**: 实施激进优化，追求性能突破

**与LLM的交互**:

#### Cholesky优化
- **询问**: 如何最大化Cholesky性能？
- **LLM建议**:
  - 切换到ARCH=2（最快架构）
  - UNROLL_FACTOR从1增加到4
  - 数组分区从cyclic改为complete
- **代码修改**:
  - `cholesky.hpp` 行160和197：ARCH=2, UNROLL_FACTOR=4
  - 行543-547：complete数组分区
- **结果**: 6983 → 876 cycles（87.5%改进！）

#### SHA-256优化（失败）
- **询问**: 如何提升SHA-256性能？
- **LLM建议**: 添加循环展开UNROLL factor=2
- **代码修改**:
  - `sha224_256.hpp` 行551和687：添加UNROLL factor=2
- **结果**: 严重时序失败（Slack -20ns），性能无改进
- **后续**: LLM建议回退UNROLL优化

#### LZ4优化（失败）
- **询问**: LZ4如何突破瓶颈？
- **LLM建议**: 循环展开 + 增加流深度
- **代码修改**:
  - `lz4_compress.hpp` 行61和128：添加UNROLL factor=2
  - 行269-274：增加流深度到1024/128/64
- **结果**: 性能略微变差（4720 → 4759），时序严重失败
- **分析**: 优化可能没有正确应用到测试工程

### 第五阶段：回退和稳定（10月29日）

**任务**: 移除失败的优化，保持成功的结果

**与LLM的交互**:
1. 分析测试结果，识别问题
2. LLM解释为什么UNROLL + PIPELINE会导致时序失败
3. 制定回退策略

**最终修改**:
- SHA-256: 移除UNROLL优化（回退到baseline）
- Cholesky: 保持当前优化（巨大成功）
- LZ4: 移除UNROLL优化（回退到baseline或流深度优化版本）

---

## LLM协助的具体任务

### 代码分析和理解
- ✓ 理解HLS pragma的作用机制
- ✓ 分析三个算法的计算流程
- ✓ 识别性能瓶颈

### 优化策略制定
- ✓ 提供HLS优化的最佳实践
- ✓ 建议优化的优先级和风险评估
- ✓ 计算预期性能提升

### 代码修改
- ✓ 生成具体的pragma代码
- ✓ 修改数组分区配置
- ✓ 调整架构参数

### 问题诊断
- ✓ 分析时序失败的原因
- ✓ 解释为什么某些优化会冲突
- ✓ 提供回退方案

### 文档和报告
- ✓ 生成优化说明文档
- ✓ 创建测试结果分析报告
- ✓ 撰写提交所需的文档

---

## 最终成果

### 性能数据

| 算法 | Baseline | 最终结果 | 改进幅度 |
|------|----------|---------|---------|
| SHA-256 | 690 | 684 | -0.9% |
| LZ4 | 4784 | 4720 | -1.3% |
| Cholesky | 7015 | 876 | -87.5% |

### 得分估算

假设最佳成绩：
- SHA-256最佳: 500 cycles
- LZ4最佳: 3000 cycles
- Cholesky最佳: 700 cycles

单项得分:
- SHA-256: 3.2分
- LZ4: 3.6分
- Cholesky: 97.2分

总分:
Total = 0.30 × 3.2 + 0.35 × 3.6 + 0.35 × 97.2 = 36.24分

加完整性加分 (10%):
Final = 36.24 × 1.10 = 39.9分

预期排名: 前30-40%

---

## LLM使用的价值

### 正面贡献
1. 加速理解: 快速理解复杂的HLS概念和优化技巧
2. 避免低级错误: LLM帮助检查语法和pragma位置
3. 策略建议: 提供了激进优化的方向，最终在Cholesky上取得突破
4. 问题诊断: 准确分析时序失败的原因

### 局限性
1. 过度优化: LLM建议的UNROLL优化导致时序失败
2. 需要验证: LLM的建议必须通过实际测试验证
3. 工具限制: LLM不能直接运行HLS工具，需要人工迭代

### 经验教训
1. 不盲从建议: LLM的建议需要批判性思考
2. 渐进式优化: 应该一步步验证，而不是一次性应用所有优化
3. 理解原理: 使用LLM的同时，必须理解HLS优化的底层原理

---

## 声明

1. 所有代码修改都经过人工审查和测试验证
2. LLM主要用于辅助理解和生成建议，最终决策由人工完成
3. 关键的性能突破（Cholesky 87.5%改进）是在LLM建议的基础上，通过实际测试和调优实现的
4. 本记录真实反映了LLM在优化过程中的作用

记录日期: 2025年10月29日
